# Pattern Recognition, Adv. - Assignment 4

Name: Morten D. Laursen

Student id: a0197363

## ML estimation

### Derivative of the formulas on slide 22

By assuming that $Z$ is a set of hidden continuous variables, we have the following equation:
$$
log(p(X;\theta)) = log \int p(X,Z;\theta)dz
$$
which by introducing an arbitrary distribution $q(Z)$ (called a variational distribution) transforms to this
$$
log(p(X;\theta)) = log \int q(Z) \frac{p(X,Z;\theta)}{q(Z)}dz
$$
which by Jensen's inequality is equal to:
$$
log(p(X;\theta)) \geq  \int q(Z) \frac{p(X,Z;\theta)}{q(Z)}dz
$$
when it's true that $q^*(Z)  = p(Z|X;\theta)$ (which is the expectation-step of the algorithm). And thus by rearranging we get
$$
log(p(X;\theta)) = \int q(Z)log(p(X,Z;\theta))dz-\int q(Z)log(q(Z))
$$
and because the max of $\theta$ is found when the second term vanishes, the lower bound is equal to the log likelihood, and thus the derivations will only focus on the first term.

For easier readability we assume that $Z$ is a set of hidden *discrete* values, and thus the summation will be used instead of the integral, and thus we have log maximum likelihood:
$$
ln(p(X|\pi, \mu, \Sigma)) = \sum_{n=1}^Nln \left ( \sum_{k=1}^K\pi_k \mathcal{N}(x_n|\mu_k, \Sigma_k)  \right)
$$
where $X$ is the observed data, $\pi$ is the mixing ratio (also known as the prior), $\mu$ is the mean, $\Sigma$ is the covariance, $N$ is the amount of observations, $K$ is the dimensionality of the observations and $\mathcal{N}$ denotes the normal distribution with $\mu$ and $\Sigma$. 

#### Mean

By setting the derivative of equation (5) with regards to $\mu$, and setting this to 0, we obtain the follow equation by utilizing equation 394 from The Matrix Cookbook [https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf](https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf) and reearanging:
$$
- \sum_{n=1}^N \frac{\pi_k \mathcal{N}(x_n|\mu_k,\Sigma_k)}{\Sigma_j\pi_j\mathcal{N}(x_n|\mu_j)}\Sigma_k(x_n-\mu_k) = 0
$$
and when summing over the term $\Sigma_j\pi_j \mathcal{N}(x_n|\mu_j)$ this is equal to the corresponding posteriors, for each observed value, also denoted by $\gamma(z_{nk})$, we have:
$$
- \sum_{n=1}^N \frac{\pi_k \mathcal{N}(x_n|\mu_k,\Sigma_k)}{\gamma(z_{nk})}\Sigma_k(x_n-\mu_k) = 0
$$
By rearranging we get:
$$
\mu_k = \frac{\sum_{n=1}^N \gamma(z_{nk})x_n}{\sum_{n=1}^N \gamma(z_{nk})}
$$
and by the equations on slide 22, we have:

$$
S_k[1] = \sum_{n=1}^N\gamma_{nk}
$$

$$
S_k[x]=\sum_{n=1}^N\gamma_{nk}x_n
$$

$$
S_k[xx^\intercal]=\sum_{n=1}^N\gamma_{nk}x_nx_n^\intercal
$$
and
$$
\mu_k^*=\frac{S_k[x]}{S_k[1]}
$$
Substituting equation 9 and 10 into 12, equation 12 is equal to equation 8, and thus the equation on the slide is proved and
$$
\mu_k = \mu_k^*
$$



#### Variance

By the same approach as above, and setting the derivative of equation 5, with regards to $\Sigma$ and by utilizing equation 396 on the [matrix cookbook](https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf) we obtain and rearranging we get
$$
\Sigma_k = \frac{\sum_{n=1}^N \gamma(z_{nk})(x_n-\mu_k)(x_n-\mu_k)^\intercal} {\sum_{n=1}^N \gamma(z_{nk})}
$$
and by moving $\mu$ outside the parenthesis, we get:
$$
\Sigma_k = \frac{\sum_{n=1}^N \gamma(z_{nk})(x_n)(x_n)^\intercal} {\sum_{n=1}^N \gamma(z_{nk})}-\mu_k\mu_k^\intercal
$$


and on slide 22, we have
$$
\Lambda_k^{-1^{*}}=\frac{S_k[xx^\intercal]}{S_k[1]}-\mu_k\mu_k^\intercal
$$
and by substituting equation 9 and 11 into 16, equation 15 is equal to equation 16, and thus the equation on the slide is proved and
$$
\Sigma_k=\Lambda_k^{-1^*}
$$


#### Mixing ratio

When maximizing equation 5, which regards to the mixing ratio, we again use the matrix cookbook and this time equation 392 and we get
$$
\pi_k = \frac{\sum_{n=1}^N \gamma(z_{nk})} {\sum_{n=1}^N \gamma(z_{nk})\pi_j}
$$
And because we have a constraint that $\pi$ must sum to 1, the denominator collapses to $N$:
$$
\pi_k = \frac{\sum_{n=1}^N \gamma(z_{nk})} {N}
$$


And thus the mixing ratio is calculated by taking the mean of each class. From slide 22, we have
$$
\pi_k^*=\frac{S_k[1]}{S.[1]}
$$
by substituting equation 9 into 20, we and by $S.[1] = N$, we have proved the equation on the slide and
$$
\pi_k = \pi_k^*
$$


### Implementation of EM

#### Initialization

Assuming we have a dataset consisting of $N$ observations generated by a Gaussian Distribution, we initialize size $N$, by taking the number of observations. We initialize $\mu$ with two random observations (in my implementation, we pick the first 2). $\Sigma$ is initialized by assigning $\Sigma\{k\}$ to the covariance of the entire dataset for each cluster. And then we set the priors $\pi$ to be $0.5,\ 0.5$, by assuming that half of the points will belong to the first cluster and vice versa. 

```octave
% Get number of observations
N = size(X,1);

% Initialize mu with the two first datapoints.
mu = X([1 2], :);

% Initialize the covariance matrix for each cluster to be equal to the covariance of the full data set
sigma = [];
for (j = 1 : K)
    sigma{j} = cov(X);
end

%I Initlize the prior probability for each data point. We are assuming that the probability is equal
prior = [.5 .5];
```

Next we have our estimation step

#### Estimation step

We begin by initializing our $\theta$ (denoted by w, in the code and will be known as *weights* in the following). After this we compute the probability distribution for each cluster, by taking the current mean $\mu$ and the current covariance $\Sigma$ of the particular cluster, that we are working with. Afterwards we multiply each value by our prior $\pi$ to get our posterior, and we end up by normalizing our posterior, so that we'll get a value between 0 and 1, that sums up to 1 for each observation regarding which cluster it belongs to. 

```octave
function w = eStep(X, N, K, mu, sigma, prior)
	% initlize w, which is the matrix, that contains the probabilities for each data point, to be in cluster 1 or 2.
	% That means it should be a N x K matrix. N data points and K clusters.
	w = ones(N, K);

	% calculate the probability for each datapoint, given the the current mu and the current covariance assigned to each cluster. In first iteration the mu's are different, but the covariance are the same. We have to do this for each cluster.
	pdf = ones(N, K);
    for (j = 1 : K)
        pdf(:, j) = pdfGaussian(X, mu(j, :), sigma{j});
    end
	%multiple each value with the prior
	pdf = pdf .* prior;

	% normalizing -> makes w sum to 1.
	w = pdf ./ sum(pdf, 2);
	% done!
endfunction
```

the `pdfGaussian`-function looks as this:

```octave
function pdf = pdfGaussian(X, mu, sigma)
	% To make it eassier, we subtract the mean from each datapoint in X immediately
	X = X-mu;
	pdf = (1 / sqrt((2*pi)^2 * det(sigma))) * (exp(-1/2 * sum((X * inv(sigma) .* X),2)));
endfunction
```

and utilizes that the form of the gaussian is:
$$
g_j(x)=\frac{1}{\sqrt{(2\pi)^n|{\Sigma_j|}}}e^{-\frac{1}{2}(x-\mu_j)^\intercal\Sigma_j^{-1}(x-\mu_j)}
$$

#### Maximization step

In the maximization step we run through each cluster, and calculates the parameters derived in the previous section.

The new prior $\pi$ is calculated by using the new weights estimated by the estimation step, by taking the sum of each weight-column and dividing it by the total number of observations, $N$.  

$\mu$ is calculated from equation equation 8, by taking each column of the weights (the posterior), multiplying it by the original data $X$ and then dividing each element in the column by the sum of weights.

$\Sigma$ is calculated by getting the contribution to the covariance from each value, and thus is calculated value by value (row by row in each column). We take the current weight, multiply it with the original data minus the current mean squared. When we have run through all the values of the weights, we divide the sigma for each column by the sum of the weights in each column. 

Thus we have:

```octave
function [prior, mu, sigma] = mStep(w, N, K, mu, sigma, X, prior)
	prior = sum(w)/N; % new prior 1x2
	for (j = 1 : K)
		mu(j, :) = (w(:,j)' * X) ./ sum(w);

		% To make it eassier, we subtract mu from X
		X_mu = X - mu(j,:);

		% And then we compute the contribution covariance for each row in X
		sigma_ = zeros(2, 2);
		for (i = 1 : N)
			sigma_ = sigma_ + (w(i, j) .* (X_mu(i, :)' * X_mu(i, :)));
		end
		sigma{j} = sigma_ ./ sum(w(:, j));
	end
endfunction
```

#### Putting it all together

When putting is all together we first run our initialization. Then we set an arbitrary number of iterations and checks for convergence by comparing the means after each e- and m-step. 

```octave
for(i = 1 : 1000)
	w = eStep(X, N, K, mu, sigma, prior);

	mu_ = mu;
	[prior, mu, sigma] = mStep(w, N, K, mu, sigma, X, prior);

	if(converged(mu, mu_, 0.00001))
		break;
	end
end
```

And the convergence function, looks like this:

```octave
function converged = converged(mu, mu_, epsilon)
	converged = all(abs(mu-mu_) <= epsilon);
end
```

When the function has converged we are done.



**INSERT SCREENSHOTS!**





## Bayesian estimation

### Derivative of the formulas on slide 46



### Implementation of VB

